{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Read Chrome history by python\n",
    "##3.1  import sqlite3\n",
    "* 為了讀SQLite檔案，必須import sqlite3函式庫，該函式庫為Python安裝時所內建的函式庫，只需import不用另外安裝。\n",
    "* 把下載下來的History檔案放在同資料中如下圖即可讀取。之後參見https://docs.python.org/2/library/sqlite3.html，\n",
    "* 該文件的內容說明了sqlite3這個函式庫可以讓使用者建立table、寫入資料並讀取資料庫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PUT ALL IMPORTED PACKAGE HERE\n",
    "import sqlite3\n",
    "import datetime\n",
    "# import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to a sqlite3 db and make query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONNECT TO sqlite3 db\n",
    "def initDB(dbname):\n",
    "    conn=sqlite3.connect(dbname)\n",
    "    cu=conn.cursor()\n",
    "    return conn, cu\n",
    "\n",
    "# SEND A SQL QUERY TO THE CONNECTION\n",
    "def query(cu, sql):\n",
    "    cu.execute(sql)\n",
    "    res=cu.fetchall()\n",
    "    print \"[COMMAND(num_of_res=%d)]:%s\"%(len(res), sql)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 查詢一：我希望從urls這個表格中把visit_count和url這兩個欄位的資料給選擇出來，並且按照url這個欄位進行排序。\n",
    "        select visit_count, url from urls order by url \n",
    "* 查詢二：我希望從visits這個表格中把所有的visit給找出來，並且找出url, visit_time(拜訪時間), from_visit(從哪個URL跳過來), transition(怎麼跳過來), visit_duration(拜訪多久)。且所有的結果照著id來排序。\n",
    "        select url,visit_time, from_visit, transition, visit_duration from visits order by id ;\n",
    "* 查詢三：我希望整合visits和urls這兩個表的資料，依據是visits表的url等於urls表的id。同時找出visits表的拜訪時間、拜訪時間長，以及這個urls表的url（因為visits表的url存的是一個編碼）。\n",
    "        SELECT visits.id, visits.visit_time, visits.visit_duration, urls.url FROM visits INNER JOIN urls ON visits.url=urls.id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[COMMAND(num_of_res=14659)]:select visit_count, url from urls order by url ;\n",
      "874\thttp://mail.google.com/\n",
      "654\thttps://www.facebook.com/\n",
      "500\thttp://www.facebook.com/\n",
      "429\thttps://mail.google.com/\n",
      "407\thttps://mail.google.com/mail/\n",
      "403\thttps://mail.google.com/mail/u/0/\n",
      "292\thttps://mail.google.com/mail/u/0/#label/%5Bntnulib%5D\n",
      "270\thttp://comic.sfacg.com/\n",
      "255\thttp://www.yahoo.com.tw/\n",
      "219\thttp://tw.yahoo.com/\n"
     ]
    }
   ],
   "source": [
    "conn, cu = initDB(\"../../log_ChromeHistory/History\")\n",
    "res = query(cu, \"select visit_count, url from urls order by url ;\")\n",
    "# res = query(cu, \"select url,visit_time, from_visit, transition, visit_duration from visits order by id ;\") # return top 100 elements\n",
    "# res = query(cu, \"SELECT visits.id, visits.visit_time, visits.visit_duration, urls.url FROM visits INNER JOIN urls ON visits.url=urls.id;\")\n",
    "for r in sorted(res, reverse=True)[:10]:\n",
    "    print \"%s\\t%s\"%(r[0], r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you need to check all tables in the sqlite3, run the following code\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def show_table(cu, name=\"%\"):\n",
    "    sql=\"SELECT * FROM sqlite_master WHERE type='table' and name like '%s';\"%(name)\n",
    "    return query(cu, sql)\n",
    "# tb = show_table(cu) # return all table\n",
    "# tb = show_table(cu, 'urls') # return table with name like urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 網址處理\n",
    "* 注意看下面query後的結果，顯然如果是mail.google.com開頭的網址，應該都算進mail.google.com就好，不要有那麼多個不一樣的網址。\n",
    "        874\thttp://mail.google.com/\n",
    "        654\thttps://www.facebook.com/\n",
    "        500\thttp://www.facebook.com/\n",
    "        429\thttps://mail.google.com/\n",
    "        407\thttps://mail.google.com/mail/\n",
    "        403\thttps://mail.google.com/mail/u/0/\n",
    "        292\thttps://mail.google.com/mail/u/0/#label/%5Bntnulib%5D\n",
    "        270\thttp://comic.sfacg.com/\n",
    "        255\thttp://www.yahoo.com.tw/\n",
    "        219\thttp://tw.yahoo.com/\n",
    "* 所以我現在希望能夠把前面開頭是mail.google.com的都算成是拜訪同一個網址，並且累計總共拜訪幾次。\n",
    "* 相當於要建一個dictionary 把網址前段mapping到出現次數的加總。\n",
    "* 而現在的問題是要怎麼把網址斷開？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## string operations\n",
    "* 各位是否還記得我們曾經看過一個程式如下，他用sentences.split()把所有的字通通斷開了。\n",
    "    1. 把所有的奇怪的字元刪除，包含\n",
    "        >!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "            sentences = sentences.translate(None, string.punctuation)\n",
    "    2. 把所有的字轉小寫\n",
    "            sentences = sentences.lower()\n",
    "    3. 把要輸入的字串依照空白斷開\n",
    "            wordlist = sentences.split()\n",
    "    4. 用for-each讀取wordlist中的每一個word，看他出現幾次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 will\n",
      "8 you\n",
      "8 stars\n",
      "7 the\n",
      "7 be\n",
      "7 are\n",
      "5 for\n",
      "4 that\n",
      "4 of\n",
      "4 in\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d3af97d4a909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# hist:histogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import string\n",
    "sentences = 'All men have stars, but they are not the same things for different people. For some, who are travelers, the stars are guides. For others they are no more than little lights in the sky. For others, who are scholars, they are problems... But all these stars are silent. You-You alone will have stars as no one else has them... In one of the stars I shall be living. In one of them I shall be laughing. And so it will be as if all the stars will be laughing when you look at the sky at night..You, only you, will have stars that can laugh! And when your sorrow is comforted (time soothes all sorrows) you will be content that you have known me... You will always be my friend. You will want to laugh with me. And you will sometimes open your window, so, for that pleasure... It will be as if, in place of the stars, I had given you a great number of little bells that knew how to laugh'\n",
    "sentences = sentences.translate(None, string.punctuation)\n",
    "sentences = sentences.lower()\n",
    "wdict = {}\n",
    "for word in sentences.split():\n",
    "    if not wdict.has_key(word):\n",
    "        wdict[word] = 0\n",
    "    wdict[word] += 1\n",
    "for f, q in sorted(((freq, word) for word, freq in wdict.items()), reverse=True)[:10]:\n",
    "    print f, q\n",
    "plt.hist(wdict.values(), facecolor='green', alpha=0.5)# hist:histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mail.google.com\n"
     ]
    }
   ],
   "source": [
    "urlstr = 'https://mail.google.com/mail/u/0/#label/%5Bntnulib%5D'\n",
    "# print urlstr.split('/')\n",
    "urlseq = urlstr.split('/')\n",
    "print urlseq[2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def top_n_url(cu, n=10):\n",
    "    res_list = []\n",
    "    url_dict = {}\n",
    "    res = query(cu, \"select visit_count, url from urls order by url ;\")\n",
    "    for item in res:\n",
    "        urlseg = item[1].split('/')\n",
    "        try:\n",
    "            url_dict.setdefault(urlseg[2], 0)\n",
    "            url_dict[urlseg[2]] += item[0]\n",
    "        except:\n",
    "            pass\n",
    "    res_list = url_dict.items()\n",
    "    res_list.sort(key=lambda s:s[1], reverse=True)\n",
    "    for r in res_list[:10]:\n",
    "        print r\n",
    "    return res_list\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "res = top_n_url(cu, 10) # return top 100 elements with default sql command\n",
    "# res = top_n_url(cu, None) # return all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
